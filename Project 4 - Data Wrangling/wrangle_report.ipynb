{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6104ad",
   "metadata": {},
   "source": [
    "## Project 4 - Data Wrangling With Twitter 'We Rate Dogs' Data\n",
    "\n",
    "### Project Setup\n",
    "\n",
    "The project data had to be gathered from three different sources:\n",
    "* a csv-file (twitter-archive-enhanced.csv) directly provided within the workspace\n",
    "* a tsv-file (image-predictions.tsv) to download programmaticaly via python request from a provided url.\n",
    "* tweet-data to be gathered progammatically via twitter's api (python module tweepy) based on available tweet-ids in the twitter archive\n",
    "\n",
    "After gathering the content had to be assessed for quality and tidiness and afterwards cleaned.\n",
    "\n",
    "\n",
    "### Gathering\n",
    "\n",
    "* The downloaded file `twitter-archive-enhanced.csv` is directly loaded into a pandas dataframe using `pandas` `read_csv` function. \n",
    "* The `image-prediction.tsv` file is accessed via python's request module and then saved to a file that afterwards is again loaded via `read_csv`\n",
    "* For downloading data from twitter via `tweepy` I had to register first as twitter developer to get the necessary user and access keys and secrets. After twitter's confirmation I tried to download additional data for all by tweet_ids in the `twitter archive` dataset. Most of the data could be accessed and saved to a JSON file. For several tweets the download failed with an error message telling that the respective tweet wasn't available or (once) access rights were missing. After a quick look on the failed data I saw that tweet_ids sometimes didn't match to other data of the tweet. This had to be assessed later. Via `pandas` `read_json` function the JSON file could also be loaded into a dataframe.\n",
    "\n",
    "### Assessing\n",
    "\n",
    "Based on the gathering I started with three different dataframes, `image_predictions`, `tweed_data` and `twitter_archive`. At first I looked for information about the data. For the `image_predictions` dataset this was provided in the project description, for `tweed_data` I found respective information [here](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet), for `twitter_archive` no information was provided but could be derived from twitter's api description as well.  \n",
    "  \n",
    "First I assesed the dataframes visually by displaying data via pandas `.head()` function. Later I started to assess programmatically using `.info()` to get information about datatypes and null values. Every finding was briefly described in the findings section for later cleaning.  \n",
    "There were many data quality issues in particular in the `twitter_archive` dataset. Besides common issues like erroneous data types or missing values I found some harder to clean aspects like wrong ratings which obviously come from parsing errors or - even more severe - wrong tweed_ids\n",
    "  \n",
    "Besides quality, tidiness of data is a big issue, too. This starts with having values instead of categories as columns (Floofer,...) or different names for columns with same content in different datasets and ranges up to having data 'containers' in columns like `extended_entities` that should be transferred to own tables.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "Based on the findings I started to clean data using the describe, code, test approach. First I made copies of the dataset to not lose the original data. I focused on merging dataframes as soon as possible, so that I then could focus on dependencies within a single dataset.\n",
    "Normally I would have focused on cleaning the wrong tweed-ids but decided not to due to lack of time for the project. Finally I saved the cleaned `twitter_archive_clean` dataset to `twitter_archive_master.csv` for later analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Data_Analyst] *",
   "language": "python",
   "name": "conda-env-Data_Analyst-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
